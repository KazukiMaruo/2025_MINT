{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~ Libraries\n",
    "import sys, os\n",
    "import mne # Python package for processing and analyzing electrophysiological data\n",
    "import numpy as np\n",
    "from glob import glob # look for all the pathnames matching a specified pattern according to the rules\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing import ICA # ICA (Independent Component Analysis) algorithm, which is for artifact removal\n",
    "from autoreject import AutoReject # Python package for automatically rejecting bad epochs in EEG/MEG data\n",
    "import json\n",
    "import owncloud\n",
    "import pandas as pd\n",
    "import braindecode\n",
    "import torch\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict, cross_validate, StratifiedKFold\n",
    "\n",
    "# Deep learning\n",
    "from braindecode.models import EEGNetv4\n",
    "from braindecode.preprocessing import exponential_moving_standardize\n",
    "from braindecode.util import set_random_seeds\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "# ~~~~~~~~~~~~~~ Libraries ~~~~~~~~~~~~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual data of sub-03 is processed\n",
      "EEGNET parameters:\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~ Parameters\n",
    "group = 'adult'\n",
    "modality = 'visual' # 'visual' or 'audio'\n",
    "subject = 'sub-04'\n",
    "\n",
    "# EEGNET parameters\n",
    "# Load the JSON file\n",
    "code_directory = os.path.dirname(\"/u/kazma/MINT/code/1st-level\")\n",
    "sys.path.append(code_directory) \n",
    "os.chdir(os.path.dirname(\"/u/kazma/MINT/code/1st-level\"))\n",
    "print(os.getcwd())\n",
    "with open(\"config.json\") as f: # import variables from config.json\n",
    "    config = json.load(f) \n",
    "globals().update(config)\n",
    "\n",
    "\n",
    "# Print out each parameter\n",
    "print(f\"{modality} data of {subject} is processed\")\n",
    "print(\"EEGNET parameters:\")\n",
    "print(f\"====== CV: {EEGNET_CV}\")\n",
    "print(f\"====== Max epochs: {EEGNET_MAX_EPOCHS}\")\n",
    "print(f\"====== Batch size: {EEGNET_BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~ Set the working directory\n",
    "path = f\"{COMPUTE_DIR}/data/{group}/interim/{modality}\"\n",
    "sub_folders = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
    "sub_folders_sorted = sorted(sub_folders, key=lambda x: int(re.search(r'\\d+', x).group())) # Sort the folders based on the numeric part after \"sub-\"\n",
    "# ~~~~~~~~~~~~~~ Set the working directory ~~~~~~~~~~~~~~\n",
    "\n",
    "# ~~~~~~~~~~~~~~ Concatanating 3 sessions\n",
    "each_sub_path = f\"{COMPUTE_DIR}/data/{group}/interim/{modality}/{subject}\"\n",
    "each_sub_folders = [f for f in os.listdir(each_sub_path) if os.path.isdir(os.path.join(each_sub_path, f))]\n",
    "each_sub_folders_sorted = sorted(each_sub_folders, key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "\n",
    "eegdata_dict = {}\n",
    "for x,ses_loop in enumerate(each_sub_folders_sorted):\n",
    "    sub_filename = os.path.join(path, subject, ses_loop, 'epochs-epo.fif') \n",
    "    epochs = mne.read_epochs(sub_filename, preload=True)\n",
    "    eegdata_dict[ses_loop] = epochs\n",
    "\n",
    "# concatanate all 3 sessions into 1 epoch\n",
    "epochs = mne.concatenate_epochs([eegdata_dict['ses-01'], eegdata_dict['ses-02'], eegdata_dict['ses-03']])\n",
    "# ~~~~~~~~~~~~~~ Concatanating 3 sessions ~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Crop epochs to the desired time range\n",
    "cropped_epochs = epochs.copy().crop(tmin=EEGNET_MIN_TIME, tmax=EEGNET_MAX_TIME)\n",
    "\n",
    "# Get the info about the cropped data\n",
    "conditions = list(cropped_epochs.event_id.keys()) # list of conditions\n",
    "n_conditions = len(conditions) # number of conditions\n",
    "n_trials = len(cropped_epochs) # number of trials\n",
    "n_samples = cropped_epochs.get_data().shape[2]\n",
    "n_channels = cropped_epochs.get_data().shape[1]\n",
    "min_time = cropped_epochs.times[0]*1000   # First time point in milli seconds\n",
    "max_time = cropped_epochs.times[-1]*1000    # Last time point in milli seconds\n",
    "\n",
    "\n",
    "print(\"=====================================================\")\n",
    "print(\"=====================================================\")\n",
    "print(\"=====================================================\")\n",
    "\n",
    "print(f\" Condition lists: {conditions}\")\n",
    "print(f\" Total trials: {n_trials}\")\n",
    "print(f\" Time points: {n_samples}\")\n",
    "print(f\" Time window (ms): {min_time} - {max_time}\")\n",
    "\n",
    "\n",
    "# check GPU availability\n",
    "cuda = torch.cuda.is_available()  # Check if a GPU is available\n",
    "device = \"cuda\" if cuda else \"cpu\"  # Use \"cuda\" if available, otherwise fallback to \"cpu\"\n",
    "\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True  # Enable cuDNN auto-tuning for performance\n",
    "\n",
    "\n",
    "# Set random seeds\n",
    "# PURPOSE: reproducibility across runs, random initializations (e.g., model weights) yield consistant results\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "\n",
    "# dictionaries for decoding accuracy\n",
    "pairwise_decoding_accuracies = {}\n",
    "# dictionaries for decoding accuracy of standard deviation\n",
    "pairwise_decoding_accuracies_std = {}\n",
    "# dictionaries for estimators\n",
    "pairwise_decoding_estimators = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(n_conditions):\n",
    "    for j in range(i + 1, n_conditions):\n",
    "\n",
    "            cond1 = conditions[i]\n",
    "            cond2 = conditions[j]\n",
    "\n",
    "            print(f\"{cond1} vs. {cond2}\")\n",
    "            \n",
    "            filtered_epochs = cropped_epochs[cond1,cond2]\n",
    "\n",
    "            # get EEG data\n",
    "            X = filtered_epochs.get_data(picks=mne.pick_types(filtered_epochs.info, eeg=True, eog=False, exclude='bads'))\n",
    "\n",
    "            # get labels (=numerosity)\n",
    "            unique_labels = np.unique(filtered_epochs.events[:,-1])\n",
    "            label_0, label_1 = unique_labels[0], unique_labels[1]  # Assign the first label to 0 and the second to 1\n",
    "\n",
    "            y = np.where(filtered_epochs.events[:, -1] == label_0, 0, 1)\n",
    "\n",
    "            skfold = StratifiedKFold(n_splits=EEGNET_CV, shuffle=True, random_state=23)\n",
    "\n",
    "            # exp. moving std. for each trial\n",
    "            for s in range(X.shape[0]):\n",
    "                X[s,:,:] = exponential_moving_standardize(X[s,:,:], factor_new=0.001, init_block_size=None, eps=1e-4)\n",
    "\n",
    "            # create the model\n",
    "            net = EEGClassifier(\n",
    "                \"EEGNetv4\", \n",
    "                            module__n_chans=n_channels, # Number of EEG channels\n",
    "                            module__n_outputs=2,               # Number of outputs of the model. This is the number of classes in the case of classification.\n",
    "                            module__n_times=n_samples,         # Number of time samples of the input window.\n",
    "                            module__final_conv_length='auto',  # Length of the final convolution layer. If \"auto\", it is set based on the n_times.\n",
    "                            module__pool_mode='mean',          # Pooling method to use in pooling layers\n",
    "                            module__F1=8,                      # Number of temporal filters in the first convolutional layer.\n",
    "                            module__D=2,                       # Depth multiplier for the depthwise convolution.\n",
    "                            module__F2=16,                     # Number of pointwise filters in the separable convolution. Usually set to ``F1 * D``.\n",
    "                            module__kernel_length=64,         # Length of the temporal convolution kernel. Usally sampling rate / 2 = 500/2 = 250\n",
    "                            module__third_kernel_size=(8, 4), \n",
    "                            module__drop_prob=0.25,            # Dropout probability after the second conv block and before the last layer. 0.5 for within-subject classification, 0.25 in cross-subject clasification\n",
    "                            module__chs_info=None,             # (list of dict) â€“ Information about each individual EEG channel. This should be filled with info[\"chs\"]. Refer to mne.Info for more details.\n",
    "                            module__input_window_seconds=None, # Length of the input window in seconds.\n",
    "                            module__sfreq=SFREQ,\n",
    "                            max_epochs=EEGNET_MAX_EPOCHS,\n",
    "                            batch_size=EEGNET_BATCH_SIZE,\n",
    "                            train_split=None,\n",
    "            )\n",
    "\n",
    "\n",
    "            cvs = cross_validate(net, \n",
    "                                X, \n",
    "                                y, \n",
    "                                scoring=\"accuracy\", # for balanced classes, this corresponds to accuracy,\n",
    "                                # chance level might be 0 (adjusted = False), or 0.X (adjusted = True)\n",
    "                                cv=skfold, \n",
    "                                n_jobs=-1, # only 1 to avoid overload in parallel jobs, in non-par jobs it could be -1\n",
    "                                return_estimator=True, # if you need the model to estimate on another test set\n",
    "                                return_train_score=False,\n",
    "                                )\n",
    "            \n",
    "            pairwise_decoding_accuracies[(cond1,cond2)] = np.mean(cvs['test_score'])\n",
    "            pairwise_decoding_accuracies_std[(cond1,cond2)] = np.std(cvs['test_score'])\n",
    "            pairwise_decoding_estimators[(cond1,cond2)] = cvs['estimator']\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~ Save the decoding accuracy\n",
    "save_folder = f\"{COMPUTE_DIR}/data/{group}/processed/{modality}/{subject}\"\n",
    "save_path = os.path.join(save_folder, \"EEGNet_accuracy_pairwise.pkl\") #  a pickle file\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(pairwise_decoding_accuracies, f)\n",
    "print(f\"{subject}: saved in 'EEGNet_accuracy_pairwise.pkl'\")\n",
    "# ~~~~~~~~~~~~~~~~ Save the decoding accuracy ~~~~~~~~~~~~~~~~\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~ Save the decoding accuracy standard deviation\n",
    "save_path = os.path.join(save_folder, \"EEGNet_accuracy_std_pairwise.pkl\") #  a pickle file\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(pairwise_decoding_accuracies_std, f)\n",
    "print(f\"{subject}: saved in 'EEGNet_accuracy_std_pairwise.pkl'\")\n",
    "# ~~~~~~~~~~~~~~~~ Save the decoding accuracy standard deviation ~~~~~~~~~~~~~~~~\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~ Save the EEGNet estimation\n",
    "save_path = os.path.join(save_folder, \"EEGNet_pairwise_estimator.pkl\") #  a pickle file\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(pairwise_decoding_estimators, f)\n",
    "print(f\"{subject}: saved in '_EEGNet_pairwise_estimator.pkl'\")\n",
    "# ~~~~~~~~~~~~~~~~ Save the EEGNet estimation ~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MINT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
